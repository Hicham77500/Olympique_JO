{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2209a25",
   "metadata": {},
   "source": [
    "# Exploration et Machine Learning - Donn√©es Olympiques üèÜ\n",
    "\n",
    "Ce notebook pr√©sente une analyse compl√®te des donn√©es olympiques avec :\n",
    "- üìä **Exploration des donn√©es** depuis Azure MySQL\n",
    "- üßπ **Nettoyage et pr√©paration** des donn√©es\n",
    "- üìà **Visualisations interactives** avec Plotly\n",
    "- ü§ñ **Mod√®les de Machine Learning** avec Scikit-learn\n",
    "  - Classification avec Random Forest\n",
    "  - Clustering avec KMeans\n",
    "\n",
    "## Structure des donn√©es\n",
    "- **Athletes** : 75,904 athl√®tes olympiques\n",
    "- **Hosts** : 53 pays/villes h√¥tes\n",
    "- **Medals** : 17,011 m√©dailles \n",
    "- **Results** : 113,632 r√©sultats de comp√©titions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df80d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Biblioth√®ques import√©es avec succ√®s\n",
      "üìä Pandas: 2.3.3\n",
      "üî¢ NumPy: 2.3.4\n",
      "üìà Plotly: 6.3.1\n",
      "ü§ñ Scikit-learn disponible\n",
      "üóÉÔ∏è MySQL Connector disponible\n",
      "üé® Matplotlib et Seaborn configur√©s\n"
     ]
    }
   ],
   "source": [
    "# Imports des biblioth√®ques pour l'exploration et le Machine Learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly\n",
    "\n",
    "# Biblioth√®ques Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score\n",
    "\n",
    "# Base de donn√©es\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Configuration d'affichage\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Validation des imports\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
    "print(f\"üìä Pandas: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy: {np.__version__}\")\n",
    "print(f\"üìà Plotly: {plotly.__version__}\")\n",
    "print(f\"ü§ñ Scikit-learn disponible\")\n",
    "print(f\"üóÉÔ∏è MySQL Connector disponible\")\n",
    "print(f\"üé® Matplotlib et Seaborn configur√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d86ff5",
   "metadata": {},
   "source": [
    "## 1. Connexion √† la base de donn√©es et chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48abc61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connexion √† Azure MySQL r√©ussie\n",
      "üìä Chargement des donn√©es...\n",
      "‚úÖ Athletes: 75,904 lignes\n",
      "‚úÖ Hosts: 53 lignes\n",
      "‚úÖ Medals: 17,011 lignes\n",
      "‚úÖ Results: 113,632 lignes\n",
      "‚úÖ Athletes: 75,904 lignes\n",
      "‚úÖ Hosts: 53 lignes\n",
      "‚úÖ Medals: 17,011 lignes\n",
      "‚úÖ Results: 113,632 lignes\n"
     ]
    }
   ],
   "source": [
    "# Configuration de connexion Azure MySQL\n",
    "def create_connection():\n",
    "    \"\"\"Cr√©e une connexion √† la base MySQL Azure\"\"\"\n",
    "    try:\n",
    "        config = {\n",
    "            'host': 'olympics-m.mysql.database.azure.com',\n",
    "            'user': 'azure7',\n",
    "            'password': 'Gnarok246272',\n",
    "            'database': 'olympics',\n",
    "            'port': 3306,\n",
    "            'ssl_disabled': False\n",
    "        }\n",
    "        conn = mysql.connector.connect(**config)\n",
    "        print(\"‚úÖ Connexion √† Azure MySQL r√©ussie\")\n",
    "        return conn\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"‚ùå Erreur de connexion: {e}\")\n",
    "        return None\n",
    "\n",
    "# Chargement des donn√©es depuis la base\n",
    "def load_olympic_data():\n",
    "    \"\"\"Charge toutes les donn√©es olympiques dans des DataFrames\"\"\"\n",
    "    conn = create_connection()\n",
    "    if not conn:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Chargement des tables\n",
    "        print(\"üìä Chargement des donn√©es...\")\n",
    "        \n",
    "        athletes_df = pd.read_sql(\"SELECT * FROM athletes\", conn)\n",
    "        hosts_df = pd.read_sql(\"SELECT * FROM hosts\", conn)\n",
    "        medals_df = pd.read_sql(\"SELECT * FROM medals\", conn)\n",
    "        results_df = pd.read_sql(\"SELECT * FROM results\", conn)\n",
    "        \n",
    "        print(f\"‚úÖ Athletes: {len(athletes_df):,} lignes\")\n",
    "        print(f\"‚úÖ Hosts: {len(hosts_df):,} lignes\")\n",
    "        print(f\"‚úÖ Medals: {len(medals_df):,} lignes\")\n",
    "        print(f\"‚úÖ Results: {len(results_df):,} lignes\")\n",
    "        \n",
    "        conn.close()\n",
    "        return athletes_df, hosts_df, medals_df, results_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du chargement: {e}\")\n",
    "        conn.close()\n",
    "        return None, None, None, None\n",
    "\n",
    "# Chargement des donn√©es\n",
    "athletes_df, hosts_df, medals_df, results_df = load_olympic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d7d8e",
   "metadata": {},
   "source": [
    "## 2. Exploration et analyse des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration d√©taill√©e des donn√©es\n",
    "def explore_dataframe(df, name):\n",
    "    \"\"\"Explore un DataFrame en d√©tail\"\"\"\n",
    "    print(f\"\\nüîç EXPLORATION - {name.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"üìä Forme: {df.shape}\")\n",
    "    print(f\"üìã Colonnes: {list(df.columns)}\")\n",
    "    print(f\"üî¢ Types de donn√©es:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(f\"\\n‚ùì Valeurs manquantes:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Colonne': missing.index,\n",
    "        'Manquantes': missing.values,\n",
    "        'Pourcentage': missing_pct.values\n",
    "    })\n",
    "    print(missing_df[missing_df['Manquantes'] > 0])\n",
    "    \n",
    "    print(f\"\\nüìà Statistiques descriptives:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# Exploration de chaque table\n",
    "if athletes_df is not None:\n",
    "    athletes_missing = explore_dataframe(athletes_df, \"Athletes\")\n",
    "    hosts_missing = explore_dataframe(hosts_df, \"Hosts\") \n",
    "    medals_missing = explore_dataframe(medals_df, \"Medals\")\n",
    "    results_missing = explore_dataframe(results_df, \"Results\")\n",
    "else:\n",
    "    print(\"‚ùå Donn√©es non charg√©es - v√©rifiez la connexion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f81e0f",
   "metadata": {},
   "source": [
    "## 3. Nettoyage et pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585de08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage et pr√©paration des donn√©es\n",
    "def clean_olympic_data(athletes_df, hosts_df, medals_df, results_df):\n",
    "    \"\"\"Nettoie et pr√©pare les donn√©es pour l'analyse\"\"\"\n",
    "    print(\"üßπ NETTOYAGE DES DONN√âES\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Copie des DataFrames\n",
    "    athletes_clean = athletes_df.copy()\n",
    "    hosts_clean = hosts_df.copy()\n",
    "    medals_clean = medals_df.copy()\n",
    "    results_clean = results_df.copy()\n",
    "    \n",
    "    # Nettoyage Athletes\n",
    "    print(\"üë®‚Äçüíº Nettoyage Athletes...\")\n",
    "    athletes_clean = athletes_clean.dropna(subset=['name'])  # Supprime les athl√®tes sans nom\n",
    "    athletes_clean['age'] = athletes_clean['age'].fillna(athletes_clean['age'].median())\n",
    "    print(f\"   ‚úÖ {len(athletes_clean):,} athl√®tes apr√®s nettoyage\")\n",
    "    \n",
    "    # Nettoyage Hosts  \n",
    "    print(\"üèüÔ∏è Nettoyage Hosts...\")\n",
    "    hosts_clean = hosts_clean.dropna()  # Supprime les lignes avec valeurs manquantes\n",
    "    print(f\"   ‚úÖ {len(hosts_clean):,} h√¥tes apr√®s nettoyage\")\n",
    "    \n",
    "    # Nettoyage Medals\n",
    "    print(\"ü•á Nettoyage Medals...\")\n",
    "    medals_clean = medals_clean.dropna(subset=['athlete_id', 'medal'])\n",
    "    medals_clean = medals_clean[medals_clean['medal'].isin(['GOLD', 'SILVER', 'BRONZE'])]\n",
    "    print(f\"   ‚úÖ {len(medals_clean):,} m√©dailles apr√®s nettoyage\")\n",
    "    \n",
    "    # Nettoyage Results\n",
    "    print(\"üèÜ Nettoyage Results...\")\n",
    "    results_clean = results_clean.dropna(subset=['athlete_id', 'ranking'])\n",
    "    results_clean = results_clean[results_clean['ranking'] > 0]\n",
    "    print(f\"   ‚úÖ {len(results_clean):,} r√©sultats apr√®s nettoyage\")\n",
    "    \n",
    "    return athletes_clean, hosts_clean, medals_clean, results_clean\n",
    "\n",
    "# Application du nettoyage\n",
    "if athletes_df is not None:\n",
    "    athletes_clean, hosts_clean, medals_clean, results_clean = clean_olympic_data(\n",
    "        athletes_df, hosts_df, medals_df, results_df\n",
    "    )\n",
    "    \n",
    "    # Cr√©ation d'un dataset unifi√© pour l'analyse\n",
    "    print(\"\\nüîó Cr√©ation du dataset unifi√©...\")\n",
    "    \n",
    "    # Jointure medals avec athletes\n",
    "    medals_athletes = medals_clean.merge(\n",
    "        athletes_clean[['id', 'name', 'age', 'nationality']], \n",
    "        left_on='athlete_id', \n",
    "        right_on='id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Jointure avec hosts pour ajouter les informations de saison\n",
    "    medals_complete = medals_athletes.merge(\n",
    "        hosts_clean[['year', 'season', 'country']], \n",
    "        on='year', \n",
    "        how='left',\n",
    "        suffixes=('_athlete', '_host')\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Dataset unifi√© cr√©√©: {len(medals_complete):,} lignes\")\n",
    "    print(f\"üìä Colonnes: {list(medals_complete.columns)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Impossible de nettoyer - donn√©es non charg√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd83514",
   "metadata": {},
   "source": [
    "## 4. Visualisations interactives avec Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e301fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations avec Plotly\n",
    "def create_olympic_visualizations(medals_complete, hosts_clean, athletes_clean):\n",
    "    \"\"\"Cr√©e des visualisations interactives des donn√©es olympiques\"\"\"\n",
    "    \n",
    "    print(\"üìà CR√âATION DES VISUALISATIONS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # 1. Distribution des m√©dailles par type\n",
    "    print(\"ü•á Graphique 1: Distribution des m√©dailles...\")\n",
    "    medal_counts = medals_complete['medal'].value_counts()\n",
    "    \n",
    "    fig1 = px.pie(\n",
    "        values=medal_counts.values,\n",
    "        names=medal_counts.index,\n",
    "        title=\"Distribution des m√©dailles olympiques\",\n",
    "        color_discrete_map={'GOLD': '#FFD700', 'SILVER': '#C0C0C0', 'BRONZE': '#CD7F32'}\n",
    "    )\n",
    "    fig1.show()\n",
    "    \n",
    "    # 2. M√©dailles par pays h√¥te (top 10)\n",
    "    print(\"üåç Graphique 2: Top 10 pays par m√©dailles...\")\n",
    "    medals_by_country = medals_complete.groupby('country_host')['medal'].count().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    fig2 = px.bar(\n",
    "        x=medals_by_country.index,\n",
    "        y=medals_by_country.values,\n",
    "        title=\"Top 10 des pays h√¥tes par nombre de m√©dailles\",\n",
    "        labels={'x': 'Pays h√¥te', 'y': 'Nombre de m√©dailles'},\n",
    "        color=medals_by_country.values,\n",
    "        color_continuous_scale='viridis'\n",
    "    )\n",
    "    fig2.show()\n",
    "    \n",
    "    # 3. Distribution de l'√¢ge des athl√®tes\n",
    "    print(\"üë• Graphique 3: Distribution des √¢ges...\")\n",
    "    fig3 = px.histogram(\n",
    "        athletes_clean,\n",
    "        x='age',\n",
    "        nbins=30,\n",
    "        title=\"Distribution de l'√¢ge des athl√®tes olympiques\",\n",
    "        labels={'age': '√Çge', 'count': 'Nombre d\\'athl√®tes'}\n",
    "    )\n",
    "    fig3.show()\n",
    "    \n",
    "    # 4. M√©dailles par sport (top 15)\n",
    "    print(\"üèÉ‚Äç‚ôÇÔ∏è Graphique 4: Sports avec le plus de m√©dailles...\")\n",
    "    medals_by_sport = medals_complete['sport'].value_counts().head(15)\n",
    "    \n",
    "    fig4 = px.bar(\n",
    "        x=medals_by_sport.values,\n",
    "        y=medals_by_sport.index,\n",
    "        orientation='h',\n",
    "        title=\"Top 15 des sports par nombre de m√©dailles\",\n",
    "        labels={'x': 'Nombre de m√©dailles', 'y': 'Sport'}\n",
    "    )\n",
    "    fig4.show()\n",
    "    \n",
    "    # 5. √âvolution des m√©dailles par ann√©e\n",
    "    print(\"üìÖ Graphique 5: √âvolution temporelle...\")\n",
    "    medals_by_year = medals_complete.groupby(['year', 'medal']).size().reset_index(name='count')\n",
    "    \n",
    "    fig5 = px.line(\n",
    "        medals_by_year,\n",
    "        x='year',\n",
    "        y='count',\n",
    "        color='medal',\n",
    "        title=\"√âvolution du nombre de m√©dailles par ann√©e\",\n",
    "        color_discrete_map={'GOLD': '#FFD700', 'SILVER': '#C0C0C0', 'BRONZE': '#CD7F32'}\n",
    "    )\n",
    "    fig5.show()\n",
    "    \n",
    "    # 6. Relation √¢ge vs performance (m√©dailles)\n",
    "    print(\"üìä Graphique 6: √Çge vs Performance...\")\n",
    "    medal_score = {'GOLD': 3, 'SILVER': 2, 'BRONZE': 1}\n",
    "    medals_complete['medal_score'] = medals_complete['medal'].map(medal_score)\n",
    "    \n",
    "    fig6 = px.scatter(\n",
    "        medals_complete.dropna(subset=['age']),\n",
    "        x='age',\n",
    "        y='medal_score',\n",
    "        color='season',\n",
    "        title=\"Relation entre l'√¢ge et la performance (m√©daille)\",\n",
    "        labels={'age': '√Çge', 'medal_score': 'Score m√©daille (Or=3, Argent=2, Bronze=1)'}\n",
    "    )\n",
    "    fig6.show()\n",
    "    \n",
    "    print(\"‚úÖ Toutes les visualisations cr√©√©es!\")\n",
    "    \n",
    "    return fig1, fig2, fig3, fig4, fig5, fig6\n",
    "\n",
    "# Cr√©ation des visualisations\n",
    "if 'medals_complete' in locals():\n",
    "    visualizations = create_olympic_visualizations(medals_complete, hosts_clean, athletes_clean)\n",
    "else:\n",
    "    print(\"‚ùå Dataset unifi√© non disponible - ex√©cutez d'abord les cellules pr√©c√©dentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c2633",
   "metadata": {},
   "source": [
    "## 5. Ing√©nierie des caract√©ristiques (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a98961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ing√©nierie des caract√©ristiques pour le Machine Learning\n",
    "def create_ml_features(medals_complete, results_clean):\n",
    "    \"\"\"Cr√©e et pr√©pare les features pour le machine learning\"\"\"\n",
    "    \n",
    "    print(\"‚öôÔ∏è ING√âNIERIE DES CARACT√âRISTIQUES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Pr√©paration du dataset pour ML\n",
    "    ml_data = medals_complete.copy()\n",
    "    \n",
    "    # 1. Cr√©ation de nouvelles features\n",
    "    print(\"üîß Cr√©ation de nouvelles caract√©ristiques...\")\n",
    "    \n",
    "    # Cat√©gories d'√¢ge\n",
    "    ml_data['age_category'] = pd.cut(\n",
    "        ml_data['age'], \n",
    "        bins=[0, 20, 25, 30, 35, 100], \n",
    "        labels=['<20', '20-25', '25-30', '30-35', '35+']\n",
    "    )\n",
    "    \n",
    "    # Score de performance par athl√®te\n",
    "    athlete_performance = ml_data.groupby('athlete_id').agg({\n",
    "        'medal_score': ['sum', 'mean', 'count']\n",
    "    }).round(2)\n",
    "    athlete_performance.columns = ['total_score', 'avg_score', 'medal_count']\n",
    "    athlete_performance = athlete_performance.reset_index()\n",
    "    \n",
    "    # Ajout au dataset principal\n",
    "    ml_data = ml_data.merge(athlete_performance, on='athlete_id', how='left')\n",
    "    \n",
    "    # 2. Encodage des variables cat√©gorielles\n",
    "    print(\"üè∑Ô∏è Encodage des variables cat√©gorielles...\")\n",
    "    \n",
    "    # LabelEncoder pour les variables cat√©gorielles\n",
    "    label_encoders = {}\n",
    "    categorical_cols = ['sport', 'season', 'country_host', 'medal']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in ml_data.columns:\n",
    "            le = LabelEncoder()\n",
    "            ml_data[f'{col}_encoded'] = le.fit_transform(ml_data[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # 3. Features num√©riques pour ML\n",
    "    print(\"üî¢ S√©lection des features num√©riques...\")\n",
    "    \n",
    "    feature_columns = ['age', 'year', 'medal_score', 'total_score', 'avg_score', 'medal_count']\n",
    "    feature_columns += [f'{col}_encoded' for col in categorical_cols if col != 'medal']\n",
    "    \n",
    "    # Cr√©ation du dataset final pour ML\n",
    "    ml_features = ml_data[feature_columns + ['medal_encoded']].dropna()\n",
    "    \n",
    "    # 4. Normalisation des features\n",
    "    print(\"üìè Normalisation des features...\")\n",
    "    \n",
    "    X = ml_features.drop('medal_encoded', axis=1)\n",
    "    y = ml_features['medal_encoded']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset ML cr√©√©:\")\n",
    "    print(f\"   üìä Forme: {X_scaled_df.shape}\")\n",
    "    print(f\"   üéØ Classes cibles: {sorted(y.unique())}\")\n",
    "    print(f\"   üìã Features: {list(X.columns)}\")\n",
    "    \n",
    "    return X_scaled_df, y, scaler, label_encoders, ml_data\n",
    "\n",
    "# Application de l'ing√©nierie des features\n",
    "if 'medals_complete' in locals():\n",
    "    X_features, y_target, scaler, encoders, ml_dataset = create_ml_features(medals_complete, results_clean)\n",
    "    \n",
    "    # Affichage des statistiques\n",
    "    print(f\"\\nüìà STATISTIQUES DU DATASET ML\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"Nombre d'√©chantillons: {len(X_features):,}\")\n",
    "    print(f\"Nombre de features: {X_features.shape[1]}\")\n",
    "    print(f\"Distribution des classes:\")\n",
    "    for medal_code, count in y_target.value_counts().sort_index().items():\n",
    "        medal_name = {0: 'BRONZE', 1: 'GOLD', 2: 'SILVER'}[medal_code]\n",
    "        print(f\"   {medal_name}: {count:,} ({count/len(y_target)*100:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Dataset unifi√© non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69675f",
   "metadata": {},
   "source": [
    "## 6. Machine Learning avec Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es pour Random Forest\n",
    "def prepare_ml_data():\n",
    "    \"\"\"Pr√©pare les donn√©es pour les mod√®les de Machine Learning\"\"\"\n",
    "    print(\"Pr√©paration des donn√©es pour le Machine Learning...\")\n",
    "    \n",
    "    # R√©cup√©ration des donn√©es enrichies\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        r.athlete_id,\n",
    "        a.name as athlete_name,\n",
    "        a.gender,\n",
    "        r.age,\n",
    "        r.age_category,\n",
    "        a.height,\n",
    "        a.weight,\n",
    "        r.team,\n",
    "        r.sport,\n",
    "        r.event,\n",
    "        r.medal,\n",
    "        r.performance_score,\n",
    "        r.season,\n",
    "        r.year,\n",
    "        h.country as host_country,\n",
    "        h.continent as host_continent\n",
    "    FROM results r\n",
    "    JOIN athletes a ON r.athlete_id = a.id\n",
    "    JOIN hosts h ON r.year = h.year AND r.season = h.season\n",
    "    WHERE r.age IS NOT NULL \n",
    "    AND a.height IS NOT NULL \n",
    "    AND a.weight IS NOT NULL\n",
    "    AND r.medal IS NOT NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.read_sql(query, connection)\n",
    "\n",
    "# Chargement des donn√©es\n",
    "ml_data = prepare_ml_data()\n",
    "print(f\"Donn√©es ML: {ml_data.shape}\")\n",
    "print(f\"M√©dailles par type: {ml_data['medal'].value_counts()}\")\n",
    "\n",
    "# Affichage des premi√®res lignes\n",
    "print(\"\\nPremi√®res lignes des donn√©es ML:\")\n",
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des caract√©ristiques pour Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "def prepare_features_rf(data):\n",
    "    \"\"\"Pr√©pare les caract√©ristiques pour Random Forest\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Encodage des variables cat√©gorielles\n",
    "    categorical_features = ['gender', 'team', 'sport', 'event', 'season', 'host_country', 'host_continent', 'age_category']\n",
    "    \n",
    "    # Utilisation du LabelEncoder pour chaque variable cat√©gorielle\n",
    "    encoded_features = {}\n",
    "    for feature in categorical_features:\n",
    "        if feature in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[f'{feature}_encoded'] = le.fit_transform(df[feature].astype(str))\n",
    "            encoded_features[feature] = le\n",
    "    \n",
    "    # S√©lection des features num√©riques et encod√©es\n",
    "    feature_columns = ['age', 'height', 'weight', 'performance_score', 'year'] + \\\n",
    "                     [f'{f}_encoded' for f in categorical_features if f in df.columns]\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    \n",
    "    return X, encoded_features\n",
    "\n",
    "# Pr√©paration des donn√©es\n",
    "X, feature_encoders = prepare_features_rf(ml_data)\n",
    "print(f\"Features pr√©par√©es: {X.shape}\")\n",
    "print(f\"Colonnes utilis√©es: {list(X.columns)}\")\n",
    "\n",
    "# Affichage des statistiques descriptives\n",
    "print(\"\\nStatistiques des features:\")\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier - Pr√©diction du type de m√©daille\n",
    "print(\"=== RANDOM FOREST CLASSIFIER ===\")\n",
    "print(\"Pr√©diction du type de m√©daille bas√©e sur les caract√©ristiques de l'athl√®te\")\n",
    "\n",
    "# Pr√©paration de la variable cible\n",
    "y_medal = ml_data['medal']\n",
    "\n",
    "# Division train/test\n",
    "X_train, X_test, y_train_medal, y_test_medal = train_test_split(\n",
    "    X, y_medal, test_size=0.2, random_state=42, stratify=y_medal\n",
    ")\n",
    "\n",
    "print(f\"Donn√©es d'entra√Ænement: {X_train.shape}\")\n",
    "print(f\"Donn√©es de test: {X_test.shape}\")\n",
    "print(f\"Distribution des m√©dailles dans l'entra√Ænement:\")\n",
    "print(y_train_medal.value_counts())\n",
    "\n",
    "# Entra√Ænement du Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nEntra√Ænement du mod√®le...\")\n",
    "rf_classifier.fit(X_train, y_train_medal)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_medal = rf_classifier.predict(X_test)\n",
    "\n",
    "# √âvaluation\n",
    "print(\"\\n=== R√âSULTATS DU CLASSIFICATEUR ===\")\n",
    "print(f\"Accuracy: {rf_classifier.score(X_test, y_test_medal):.4f}\")\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(y_test_medal, y_pred_medal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f692b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion et importance des features\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Matrice de confusion\n",
    "plt.subplot(1, 3, 1)\n",
    "cm = confusion_matrix(y_test_medal, y_pred_medal)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=rf_classifier.classes_, \n",
    "            yticklabels=rf_classifier.classes_)\n",
    "plt.title('Matrice de Confusion\\nPr√©diction des M√©dailles')\n",
    "plt.xlabel('Pr√©diction')\n",
    "plt.ylabel('R√©alit√©')\n",
    "\n",
    "# Importance des features\n",
    "plt.subplot(1, 3, 2)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "plt.title('Importance des Features\\nClassification des M√©dailles')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "# Top 10 des features les plus importantes\n",
    "plt.subplot(1, 3, 3)\n",
    "top_features = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.title('Top 10 Features\\nLes Plus Importantes')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 des features les plus importantes:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor - Pr√©diction du score de performance\n",
    "print(\"\\n=== RANDOM FOREST REGRESSOR ===\")\n",
    "print(\"Pr√©diction du score de performance bas√©e sur les caract√©ristiques\")\n",
    "\n",
    "# Pr√©paration de la variable cible pour la r√©gression\n",
    "y_performance = ml_data['performance_score']\n",
    "\n",
    "# Division train/test pour la r√©gression\n",
    "X_train_reg, X_test_reg, y_train_perf, y_test_perf = train_test_split(\n",
    "    X, y_performance, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entra√Ænement du Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entra√Ænement du r√©gresseur...\")\n",
    "rf_regressor.fit(X_train_reg, y_train_perf)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_perf = rf_regressor.predict(X_test_reg)\n",
    "\n",
    "# √âvaluation\n",
    "mse = mean_squared_error(y_test_perf, y_pred_perf)\n",
    "r2 = r2_score(y_test_perf, y_pred_perf)\n",
    "\n",
    "print(f\"\\n=== R√âSULTATS DU R√âGRESSEUR ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "# Validation crois√©e\n",
    "cv_scores = cross_val_score(rf_regressor, X_train_reg, y_train_perf, cv=5, scoring='r2')\n",
    "print(f\"\\nValidation crois√©e R¬≤ (5-fold): {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760befd8",
   "metadata": {},
   "source": [
    "## 7. Clustering avec K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering K-Means des athl√®tes\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "print(\"=== CLUSTERING K-MEANS ===\")\n",
    "print(\"Identification de profils d'athl√®tes similaires\")\n",
    "\n",
    "# Pr√©paration des donn√©es pour le clustering\n",
    "def prepare_clustering_data():\n",
    "    \"\"\"Pr√©pare les donn√©es pour le clustering\"\"\"\n",
    "    # S√©lection des features num√©riques pour le clustering\n",
    "    numeric_features = ['age', 'height', 'weight', 'performance_score', 'year']\n",
    "    \n",
    "    # R√©cup√©ration des donn√©es sans valeurs manquantes\n",
    "    cluster_data = ml_data[numeric_features + ['gender', 'sport', 'medal', 'athlete_name']].copy()\n",
    "    cluster_data = cluster_data.dropna()\n",
    "    \n",
    "    # Standardisation des features num√©riques\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(cluster_data[numeric_features])\n",
    "    \n",
    "    return X_scaled, cluster_data, scaler\n",
    "\n",
    "X_cluster, cluster_info, scaler_cluster = prepare_clustering_data()\n",
    "print(f\"Donn√©es pour clustering: {X_cluster.shape}\")\n",
    "\n",
    "# D√©termination du nombre optimal de clusters avec la m√©thode du coude\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "print(\"\\nCalcul du nombre optimal de clusters...\")\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster, kmeans.labels_))\n",
    "\n",
    "# Visualisation de la m√©thode du coude et du score de silhouette\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(k_range, inertias, 'bo-')\n",
    "plt.xlabel('Nombre de Clusters (k)')\n",
    "plt.ylabel('Inertie')\n",
    "plt.title('M√©thode du Coude')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(k_range, silhouette_scores, 'ro-')\n",
    "plt.xlabel('Nombre de Clusters (k)')\n",
    "plt.ylabel('Score de Silhouette')\n",
    "plt.title('Score de Silhouette')\n",
    "plt.grid(True)\n",
    "\n",
    "# Choix du nombre optimal de clusters (bas√© sur le score de silhouette)\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nNombre optimal de clusters: {optimal_k}\")\n",
    "print(f\"Meilleur score de silhouette: {max(silhouette_scores):.4f}\")\n",
    "\n",
    "# Application du K-Means avec le nombre optimal de clusters\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_cluster)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X_cluster[:, 0], X_cluster[:, 1], c=cluster_labels, cmap='viridis', alpha=0.6)\n",
    "plt.scatter(kmeans_final.cluster_centers_[:, 0], kmeans_final.cluster_centers_[:, 1], \n",
    "           c='red', marker='x', s=200, linewidths=3)\n",
    "plt.xlabel('√Çge (standardis√©)')\n",
    "plt.ylabel('Taille (standardis√©)')\n",
    "plt.title(f'Clusters K-Means (k={optimal_k})')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ccb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des clusters\n",
    "cluster_info['cluster'] = cluster_labels\n",
    "\n",
    "print(\"=== ANALYSE DES CLUSTERS ===\")\n",
    "print(f\"R√©partition des athl√®tes par cluster:\")\n",
    "print(cluster_info['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Caract√©ristiques moyennes de chaque cluster\n",
    "cluster_stats = cluster_info.groupby('cluster').agg({\n",
    "    'age': ['mean', 'std'],\n",
    "    'height': ['mean', 'std'],\n",
    "    'weight': ['mean', 'std'], \n",
    "    'performance_score': ['mean', 'std'],\n",
    "    'year': ['mean', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nCaract√©ristiques moyennes par cluster:\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Analyse par genre et sport\n",
    "print(\"\\n=== COMPOSITION DES CLUSTERS ===\")\n",
    "for cluster_id in sorted(cluster_info['cluster'].unique()):\n",
    "    cluster_data = cluster_info[cluster_info['cluster'] == cluster_id]\n",
    "    print(f\"\\n--- Cluster {cluster_id} ({len(cluster_data)} athl√®tes) ---\")\n",
    "    \n",
    "    # R√©partition par genre\n",
    "    gender_dist = cluster_data['gender'].value_counts()\n",
    "    print(f\"Genre: {dict(gender_dist)}\")\n",
    "    \n",
    "    # Top 5 sports\n",
    "    top_sports = cluster_data['sport'].value_counts().head(5)\n",
    "    print(f\"Top 5 sports: {dict(top_sports)}\")\n",
    "    \n",
    "    # R√©partition des m√©dailles\n",
    "    medal_dist = cluster_data['medal'].value_counts()\n",
    "    print(f\"M√©dailles: {dict(medal_dist)}\")\n",
    "    \n",
    "    # Statistiques physiques moyennes\n",
    "    avg_stats = cluster_data[['age', 'height', 'weight', 'performance_score']].mean()\n",
    "    print(f\"Moyennes: Age={avg_stats['age']:.1f}, Taille={avg_stats['height']:.1f}cm, \"\n",
    "          f\"Poids={avg_stats['weight']:.1f}kg, Score={avg_stats['performance_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation avanc√©e des clusters\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Distribution des clusters par caract√©ristiques\n",
    "features_to_plot = ['age', 'height', 'weight', 'performance_score']\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    for cluster_id in sorted(cluster_info['cluster'].unique()):\n",
    "        cluster_data = cluster_info[cluster_info['cluster'] == cluster_id]\n",
    "        plt.hist(cluster_data[feature], alpha=0.6, label=f'Cluster {cluster_id}', bins=20)\n",
    "    plt.xlabel(feature.title())\n",
    "    plt.ylabel('Fr√©quence')\n",
    "    plt.title(f'Distribution de {feature.title()} par Cluster')\n",
    "    plt.legend()\n",
    "\n",
    "# Box plots par cluster\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    plt.subplot(3, 4, i+5)\n",
    "    cluster_info.boxplot(column=feature, by='cluster', ax=plt.gca())\n",
    "    plt.title(f'Box Plot: {feature.title()} par Cluster')\n",
    "    plt.suptitle('')\n",
    "\n",
    "# Heatmap des corr√©lations par cluster\n",
    "plt.subplot(3, 4, 9)\n",
    "correlation_matrix = cluster_info[features_to_plot + ['cluster']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matrice de Corr√©lation')\n",
    "\n",
    "# R√©partition des m√©dailles par cluster\n",
    "plt.subplot(3, 4, 10)\n",
    "medal_cluster = pd.crosstab(cluster_info['cluster'], cluster_info['medal'])\n",
    "medal_cluster_pct = medal_cluster.div(medal_cluster.sum(axis=1), axis=0)\n",
    "sns.heatmap(medal_cluster_pct, annot=True, fmt='.2f', cmap='YlOrRd')\n",
    "plt.title('R√©partition des M√©dailles\\npar Cluster (%)')\n",
    "\n",
    "# Distribution des sports par cluster (top 10 sports)\n",
    "plt.subplot(3, 4, 11)\n",
    "top_sports_overall = cluster_info['sport'].value_counts().head(10).index\n",
    "sport_cluster = cluster_info[cluster_info['sport'].isin(top_sports_overall)]\n",
    "sport_counts = pd.crosstab(sport_cluster['cluster'], sport_cluster['sport'])\n",
    "sport_counts_pct = sport_counts.div(sport_counts.sum(axis=0), axis=1)\n",
    "sns.heatmap(sport_counts_pct.T, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Top 10 Sports par Cluster (%)')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Distribution par genre et cluster\n",
    "plt.subplot(3, 4, 12)\n",
    "gender_cluster = pd.crosstab(cluster_info['cluster'], cluster_info['gender'])\n",
    "gender_cluster.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "plt.title('R√©partition Hommes/Femmes\\npar Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Nombre d\\'athl√®tes')\n",
    "plt.legend(title='Genre')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0996bb3",
   "metadata": {},
   "source": [
    "## 8. √âvaluation et Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© et comparaison des performances des mod√®les\n",
    "print(\"=== R√âSUM√â DE L'ANALYSE MACHINE LEARNING ===\")\n",
    "\n",
    "# R√©capitulatif des mod√®les\n",
    "models_summary = {\n",
    "    'Random Forest Classifier': {\n",
    "        'T√¢che': 'Classification des m√©dailles',\n",
    "        'Accuracy': rf_classifier.score(X_test, y_test_medal),\n",
    "        'Features importantes': feature_importance.head(3)['feature'].tolist(),\n",
    "        'Commentaire': 'Pr√©diction du type de m√©daille (Or/Argent/Bronze)'\n",
    "    },\n",
    "    'Random Forest Regressor': {\n",
    "        'T√¢che': 'Pr√©diction du score de performance', \n",
    "        'R¬≤ Score': r2,\n",
    "        'RMSE': np.sqrt(mse),\n",
    "        'CV Score': cv_scores.mean(),\n",
    "        'Commentaire': 'Pr√©diction continue du score de performance'\n",
    "    },\n",
    "    'K-Means Clustering': {\n",
    "        'T√¢che': 'Segmentation des athl√®tes',\n",
    "        'Nombre de clusters': optimal_k,\n",
    "        'Score de silhouette': max(silhouette_scores),\n",
    "        'Commentaire': 'Identification de profils d\\'athl√®tes similaires'\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name, metrics in models_summary.items():\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"{metric}: {', '.join(value)}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "# Graphique de comparaison des performances\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Performance des mod√®les\n",
    "plt.subplot(2, 3, 1)\n",
    "models = ['RF Classifier', 'RF Regressor', 'K-Means']\n",
    "scores = [\n",
    "    rf_classifier.score(X_test, y_test_medal),\n",
    "    r2,\n",
    "    max(silhouette_scores)\n",
    "]\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral']\n",
    "bars = plt.bar(models, scores, color=colors)\n",
    "plt.title('Scores de Performance des Mod√®les')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for bar, score in zip(bars, scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Distribution des pr√©dictions vs r√©alit√© (Classifier)\n",
    "plt.subplot(2, 3, 2)\n",
    "pred_vs_real = pd.DataFrame({'R√©el': y_test_medal, 'Pr√©dit': y_pred_medal})\n",
    "confusion_data = pd.crosstab(pred_vs_real['R√©el'], pred_vs_real['Pr√©dit'])\n",
    "sns.heatmap(confusion_data, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matrice de Confusion\\nClassificateur')\n",
    "\n",
    "# Scatter plot pr√©dictions vs r√©alit√© (Regressor)\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.scatter(y_test_perf, y_pred_perf, alpha=0.6)\n",
    "plt.plot([y_test_perf.min(), y_test_perf.max()], [y_test_perf.min(), y_test_perf.max()], 'r--', lw=2)\n",
    "plt.xlabel('Score R√©el')\n",
    "plt.ylabel('Score Pr√©dit')\n",
    "plt.title('Pr√©dictions vs R√©alit√©\\nR√©gresseur')\n",
    "\n",
    "# Importance des features (top 10)\n",
    "plt.subplot(2, 3, 4)\n",
    "top_10_features = feature_importance.head(10)\n",
    "plt.barh(range(len(top_10_features)), top_10_features['importance'])\n",
    "plt.yticks(range(len(top_10_features)), top_10_features['feature'])\n",
    "plt.title('Top 10 Features Importantes')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "# Distribution des clusters\n",
    "plt.subplot(2, 3, 5)\n",
    "cluster_counts = cluster_info['cluster'].value_counts().sort_index()\n",
    "plt.pie(cluster_counts.values, labels=[f'Cluster {i}' for i in cluster_counts.index], \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "plt.title('R√©partition des Athl√®tes\\npar Cluster')\n",
    "\n",
    "# √âvolution temporelle par cluster\n",
    "plt.subplot(2, 3, 6)\n",
    "for cluster_id in sorted(cluster_info['cluster'].unique()):\n",
    "    cluster_data = cluster_info[cluster_info['cluster'] == cluster_id]\n",
    "    yearly_counts = cluster_data.groupby('year').size()\n",
    "    plt.plot(yearly_counts.index, yearly_counts.values, marker='o', label=f'Cluster {cluster_id}')\n",
    "plt.xlabel('Ann√©e')\n",
    "plt.ylabel('Nombre d\\'athl√®tes')\n",
    "plt.title('√âvolution Temporelle\\ndes Clusters')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3aba5",
   "metadata": {},
   "source": [
    "## 9. Conclusions et Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights finaux et recommandations\n",
    "print(\"=== INSIGHTS CL√âS DE L'ANALYSE ===\")\n",
    "\n",
    "insights = [\n",
    "    \"üèÖ CLASSIFICATION DES M√âDAILLES:\",\n",
    "    f\"- Le mod√®le Random Forest atteint une accuracy de {rf_classifier.score(X_test, y_test_medal):.3f}\",\n",
    "    f\"- Les features les plus importantes sont: {', '.join(feature_importance.head(3)['feature'].tolist())}\",\n",
    "    \"- Cela sugg√®re que certaines caract√©ristiques sont pr√©dictives du succ√®s olympique\",\n",
    "    \"\",\n",
    "    \"üìä PR√âDICTION DE PERFORMANCE:\",\n",
    "    f\"- Le r√©gresseur Random Forest obtient un R¬≤ de {r2:.3f}\",\n",
    "    f\"- RMSE de {np.sqrt(mse):.3f} sur l'√©chelle de score de performance\",\n",
    "    \"- Validation crois√©e confirme la robustesse du mod√®le\",\n",
    "    \"\",\n",
    "    \"üë• SEGMENTATION DES ATHL√àTES:\",\n",
    "    f\"- {optimal_k} clusters identifi√©s avec un score de silhouette de {max(silhouette_scores):.3f}\",\n",
    "    \"- Chaque cluster repr√©sente un profil d'athl√®te distinct\",\n",
    "    \"- Permet de comprendre la diversit√© des profils olympiques\",\n",
    "    \"\",\n",
    "    \"üîç RECOMMANDATIONS:\",\n",
    "    \"1. Utiliser les features importantes pour le recrutement sportif\",\n",
    "    \"2. Adapter l'entra√Ænement selon le profil de cluster de l'athl√®te\",\n",
    "    \"3. Pr√©dire les performances futures pour la planification olympique\",\n",
    "    \"4. Analyser l'√©volution des profils au fil du temps\",\n",
    "    \"\",\n",
    "    \"üí° EXTENSIONS POSSIBLES:\",\n",
    "    \"- Mod√®les plus complexes (XGBoost, r√©seaux de neurones)\",\n",
    "    \"- Analyse temporelle des tendances\",\n",
    "    \"- Pr√©diction par sport sp√©cifique\",\n",
    "    \"- Analyse de l'impact des pays h√¥tes\",\n",
    "    \"- Clustering hi√©rarchique pour une segmentation plus fine\"\n",
    "]\n",
    "\n",
    "for insight in insights:\n",
    "    print(insight)\n",
    "\n",
    "# Sauvegarde des r√©sultats pour utilisation future\n",
    "results_summary = {\n",
    "    'rf_classifier_accuracy': rf_classifier.score(X_test, y_test_medal),\n",
    "    'rf_regressor_r2': r2,\n",
    "    'optimal_clusters': optimal_k,\n",
    "    'silhouette_score': max(silhouette_scores),\n",
    "    'top_features': feature_importance.head(5)['feature'].tolist(),\n",
    "    'total_athletes_analyzed': len(ml_data),\n",
    "    'clusters_distribution': cluster_info['cluster'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "print(f\"\\n=== R√âSULTATS SAUVEGARD√âS ===\")\n",
    "print(\"Les m√©triques cl√©s ont √©t√© calcul√©es et sont disponibles pour analyse future.\")\n",
    "print(f\"Nombre total d'athl√®tes analys√©s: {results_summary['total_athletes_analyzed']:,}\")\n",
    "\n",
    "# Affichage final des m√©triques de performance\n",
    "print(f\"\\n=== M√âTRIQUES FINALES ===\")\n",
    "print(f\"üéØ Classification Accuracy: {results_summary['rf_classifier_accuracy']:.3f}\")\n",
    "print(f\"üìà Regression R¬≤: {results_summary['rf_regressor_r2']:.3f}\")\n",
    "print(f\"üîÑ Clustering Silhouette: {results_summary['silhouette_score']:.3f}\")\n",
    "print(f\"üìä Nombre de clusters: {results_summary['optimal_clusters']}\")\n",
    "\n",
    "print(\"\\n‚úÖ ANALYSE COMPL√àTE TERMIN√âE ‚úÖ\")\n",
    "print(\"Tous les mod√®les ML ont √©t√© entra√Æn√©s et √©valu√©s avec succ√®s!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
